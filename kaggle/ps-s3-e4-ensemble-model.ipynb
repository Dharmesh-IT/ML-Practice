{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de2b2ccd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-01-28T07:55:16.101616Z",
     "iopub.status.busy": "2023-01-28T07:55:16.100927Z",
     "iopub.status.idle": "2023-01-28T07:55:17.448442Z",
     "shell.execute_reply": "2023-01-28T07:55:17.446940Z"
    },
    "papermill": {
     "duration": 1.369328,
     "end_time": "2023-01-28T07:55:17.452048",
     "exception": false,
     "start_time": "2023-01-28T07:55:16.082720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/creditcardfraud/creditcard.csv\n",
      "/kaggle/input/playground-series-s3e4/sample_submission.csv\n",
      "/kaggle/input/playground-series-s3e4/train.csv\n",
      "/kaggle/input/playground-series-s3e4/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9859526",
   "metadata": {
    "papermill": {
     "duration": 0.019748,
     "end_time": "2023-01-28T07:55:17.486236",
     "exception": false,
     "start_time": "2023-01-28T07:55:17.466488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Downloading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a11b30d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T07:55:17.527181Z",
     "iopub.status.busy": "2023-01-28T07:55:17.525239Z",
     "iopub.status.idle": "2023-01-28T07:55:28.469993Z",
     "shell.execute_reply": "2023-01-28T07:55:28.468161Z"
    },
    "papermill": {
     "duration": 10.967714,
     "end_time": "2023-01-28T07:55:28.473950",
     "exception": false,
     "start_time": "2023-01-28T07:55:17.506236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/playground-series-s3e4/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/playground-series-s3e4/test.csv')\n",
    "submission = pd.read_csv('/kaggle/input/playground-series-s3e4/sample_submission.csv')\n",
    "addition_data = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')\n",
    "\n",
    "train_df['is_generated'] = 1\n",
    "test_df['is_generated'] = 1\n",
    "addition_data['is_generated'] = 0\n",
    "\n",
    "# addition_data = addition_data[addition_data['Class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "003b3bde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T07:55:28.517138Z",
     "iopub.status.busy": "2023-01-28T07:55:28.516448Z",
     "iopub.status.idle": "2023-01-28T07:55:28.644888Z",
     "shell.execute_reply": "2023-01-28T07:55:28.643092Z"
    },
    "papermill": {
     "duration": 0.152286,
     "end_time": "2023-01-28T07:55:28.647719",
     "exception": false,
     "start_time": "2023-01-28T07:55:28.495433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>is_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V22       V23  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ...  0.277838 -0.110474   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.638672  0.101288   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.771679  0.909412   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ...  0.005274 -0.190321   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ...  0.798278 -0.137458   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.111864  1.014480   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.924384  0.012463   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.578229 -0.037501   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.800049 -0.163298   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.643078  0.376777   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \\\n",
       "0       0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0   \n",
       "1      -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      0   \n",
       "2      -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0   \n",
       "3      -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0   \n",
       "4       0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0   \n",
       "...          ...       ...       ...       ...       ...     ...    ...   \n",
       "284802 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77      0   \n",
       "284803 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79      0   \n",
       "284804  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88      0   \n",
       "284805  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00      0   \n",
       "284806  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00      0   \n",
       "\n",
       "        is_generated  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "284802             0  \n",
       "284803             0  \n",
       "284804             0  \n",
       "284805             0  \n",
       "284806             0  \n",
       "\n",
       "[284807 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addition_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dad738f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T07:55:28.678623Z",
     "iopub.status.busy": "2023-01-28T07:55:28.678192Z",
     "iopub.status.idle": "2023-01-28T07:55:28.742063Z",
     "shell.execute_reply": "2023-01-28T07:55:28.741055Z"
    },
    "papermill": {
     "duration": 0.08249,
     "end_time": "2023-01-28T07:55:28.745027",
     "exception": false,
     "start_time": "2023-01-28T07:55:28.662537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, addition_data],axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "969d7179",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T07:55:28.777299Z",
     "iopub.status.busy": "2023-01-28T07:55:28.775979Z",
     "iopub.status.idle": "2023-01-28T07:55:28.947627Z",
     "shell.execute_reply": "2023-01-28T07:55:28.946509Z"
    },
    "papermill": {
     "duration": 0.190226,
     "end_time": "2023-01-28T07:55:28.950088",
     "exception": false,
     "start_time": "2023-01-28T07:55:28.759862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>is_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.074329</td>\n",
       "      <td>-0.129425</td>\n",
       "      <td>-1.137418</td>\n",
       "      <td>0.412846</td>\n",
       "      <td>-0.192638</td>\n",
       "      <td>-1.210144</td>\n",
       "      <td>0.110697</td>\n",
       "      <td>-0.263477</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.887840</td>\n",
       "      <td>0.336701</td>\n",
       "      <td>-0.110835</td>\n",
       "      <td>-0.291459</td>\n",
       "      <td>0.207733</td>\n",
       "      <td>-0.076576</td>\n",
       "      <td>-0.059577</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.998827</td>\n",
       "      <td>-1.250891</td>\n",
       "      <td>-0.520969</td>\n",
       "      <td>-0.894539</td>\n",
       "      <td>-1.122528</td>\n",
       "      <td>-0.270866</td>\n",
       "      <td>-1.029289</td>\n",
       "      <td>0.050198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038367</td>\n",
       "      <td>0.133518</td>\n",
       "      <td>-0.461928</td>\n",
       "      <td>-0.465491</td>\n",
       "      <td>-0.464655</td>\n",
       "      <td>-0.009413</td>\n",
       "      <td>-0.038238</td>\n",
       "      <td>84.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091535</td>\n",
       "      <td>1.004517</td>\n",
       "      <td>-0.223445</td>\n",
       "      <td>-0.435249</td>\n",
       "      <td>0.667548</td>\n",
       "      <td>-0.988351</td>\n",
       "      <td>0.948146</td>\n",
       "      <td>-0.084789</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.803736</td>\n",
       "      <td>0.154495</td>\n",
       "      <td>0.951233</td>\n",
       "      <td>-0.506919</td>\n",
       "      <td>0.085046</td>\n",
       "      <td>0.224458</td>\n",
       "      <td>0.087356</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.979649</td>\n",
       "      <td>-0.184949</td>\n",
       "      <td>-1.064206</td>\n",
       "      <td>0.120125</td>\n",
       "      <td>-0.215238</td>\n",
       "      <td>-0.648829</td>\n",
       "      <td>-0.087826</td>\n",
       "      <td>-0.035367</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079792</td>\n",
       "      <td>0.167701</td>\n",
       "      <td>-0.042939</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>-0.096148</td>\n",
       "      <td>-0.057780</td>\n",
       "      <td>-0.073839</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.025898</td>\n",
       "      <td>-0.171827</td>\n",
       "      <td>1.203717</td>\n",
       "      <td>1.243900</td>\n",
       "      <td>-0.636572</td>\n",
       "      <td>1.099074</td>\n",
       "      <td>-0.938651</td>\n",
       "      <td>0.569239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608908</td>\n",
       "      <td>0.027901</td>\n",
       "      <td>-0.262813</td>\n",
       "      <td>0.257834</td>\n",
       "      <td>-0.252829</td>\n",
       "      <td>0.108338</td>\n",
       "      <td>0.021051</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503931</th>\n",
       "      <td>NaN</td>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503932</th>\n",
       "      <td>NaN</td>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503933</th>\n",
       "      <td>NaN</td>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503934</th>\n",
       "      <td>NaN</td>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503935</th>\n",
       "      <td>NaN</td>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503936 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id      Time         V1         V2        V3        V4        V5  \\\n",
       "0       0.0       0.0   2.074329  -0.129425 -1.137418  0.412846 -0.192638   \n",
       "1       1.0       0.0   1.998827  -1.250891 -0.520969 -0.894539 -1.122528   \n",
       "2       2.0       0.0   0.091535   1.004517 -0.223445 -0.435249  0.667548   \n",
       "3       3.0       0.0   1.979649  -0.184949 -1.064206  0.120125 -0.215238   \n",
       "4       4.0       0.0   1.025898  -0.171827  1.203717  1.243900 -0.636572   \n",
       "...     ...       ...        ...        ...       ...       ...       ...   \n",
       "503931  NaN  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "503932  NaN  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "503933  NaN  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "503934  NaN  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "503935  NaN  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8  ...       V22       V23       V24  \\\n",
       "0      -1.210144  0.110697 -0.263477  ... -0.887840  0.336701 -0.110835   \n",
       "1      -0.270866 -1.029289  0.050198  ... -0.038367  0.133518 -0.461928   \n",
       "2      -0.988351  0.948146 -0.084789  ... -0.803736  0.154495  0.951233   \n",
       "3      -0.648829 -0.087826 -0.035367  ... -0.079792  0.167701 -0.042939   \n",
       "4       1.099074 -0.938651  0.569239  ...  0.608908  0.027901 -0.262813   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "503931 -2.606837 -4.918215  7.305334  ...  0.111864  1.014480 -0.509348   \n",
       "503932  1.058415  0.024330  0.294869  ...  0.924384  0.012463 -1.016226   \n",
       "503933  3.031260 -0.296827  0.708417  ...  0.578229 -0.037501  0.640134   \n",
       "503934  0.623708 -0.686180  0.679145  ...  0.800049 -0.163298  0.123205   \n",
       "503935 -0.649617  1.577006 -0.414650  ...  0.643078  0.376777  0.008797   \n",
       "\n",
       "             V25       V26       V27       V28  Amount  Class  is_generated  \n",
       "0      -0.291459  0.207733 -0.076576 -0.059577    1.98      0             1  \n",
       "1      -0.465491 -0.464655 -0.009413 -0.038238   84.00      0             1  \n",
       "2      -0.506919  0.085046  0.224458  0.087356    2.69      0             1  \n",
       "3       0.000799 -0.096148 -0.057780 -0.073839    1.00      0             1  \n",
       "4       0.257834 -0.252829  0.108338  0.021051    1.00      0             1  \n",
       "...          ...       ...       ...       ...     ...    ...           ...  \n",
       "503931  1.436807  0.250034  0.943651  0.823731    0.77      0             0  \n",
       "503932 -0.606624 -0.395255  0.068472 -0.053527   24.79      0             0  \n",
       "503933  0.265745 -0.087371  0.004455 -0.026561   67.88      0             0  \n",
       "503934 -0.569159  0.546668  0.108821  0.104533   10.00      0             0  \n",
       "503935 -0.473649 -0.818267 -0.002415  0.013649  217.00      0             0  \n",
       "\n",
       "[503936 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06d864a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T07:55:28.981498Z",
     "iopub.status.busy": "2023-01-28T07:55:28.981042Z",
     "iopub.status.idle": "2023-01-28T07:55:29.200175Z",
     "shell.execute_reply": "2023-01-28T07:55:29.198787Z"
    },
    "papermill": {
     "duration": 0.237614,
     "end_time": "2023-01-28T07:55:29.202830",
     "exception": false,
     "start_time": "2023-01-28T07:55:28.965216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.Class.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "759f7a6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T07:55:29.234977Z",
     "iopub.status.busy": "2023-01-28T07:55:29.234552Z",
     "iopub.status.idle": "2023-01-28T07:55:29.301221Z",
     "shell.execute_reply": "2023-01-28T07:55:29.299979Z"
    },
    "papermill": {
     "duration": 0.086291,
     "end_time": "2023-01-28T07:55:29.304024",
     "exception": false,
     "start_time": "2023-01-28T07:55:29.217733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.concat([train_df, test_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7f75d4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T07:55:29.336655Z",
     "iopub.status.busy": "2023-01-28T07:55:29.335637Z",
     "iopub.status.idle": "2023-01-28T07:55:29.391148Z",
     "shell.execute_reply": "2023-01-28T07:55:29.389870Z"
    },
    "papermill": {
     "duration": 0.074852,
     "end_time": "2023-01-28T07:55:29.394315",
     "exception": false,
     "start_time": "2023-01-28T07:55:29.319463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['hour'] = df['Time'] % (24 * 3600) // 3600\n",
    "df['day'] = (df['Time'] // (24 * 3600)) % 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7245dd42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T07:55:29.426342Z",
     "iopub.status.busy": "2023-01-28T07:55:29.425902Z",
     "iopub.status.idle": "2023-01-28T07:55:31.252088Z",
     "shell.execute_reply": "2023-01-28T07:55:31.250850Z"
    },
    "papermill": {
     "duration": 1.845341,
     "end_time": "2023-01-28T07:55:31.254979",
     "exception": false,
     "start_time": "2023-01-28T07:55:29.409638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def across_col_feat(df):\n",
    "    '''\n",
    "    Calculates features across colums...\n",
    "    '''\n",
    "    features = [feat for feat in df.columns if 'V' in feat]\n",
    "    df['V_Sum'] = df[features].sum(axis = 1)\n",
    "    df['V_Min'] = df[features].min(axis = 1)\n",
    "    df['V_Max'] = df[features].max(axis = 1)\n",
    "    df['V_Avg'] = df[features].mean(axis = 1)\n",
    "    df['V_Std'] = df[features].std(axis = 1)\n",
    "    df['V_Pos'] = df[features].gt(0).sum(axis = 1)\n",
    "    df['V_Neg'] = df[features].lt(0).sum(axis = 1)\n",
    "    df['V_Range'] = abs(df['V_Min'] - df['V_Max'])\n",
    "\n",
    "    return df\n",
    "\n",
    "df = across_col_feat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cad1052b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T07:55:31.289324Z",
     "iopub.status.busy": "2023-01-28T07:55:31.288418Z",
     "iopub.status.idle": "2023-01-28T07:55:31.293914Z",
     "shell.execute_reply": "2023-01-28T07:55:31.292434Z"
    },
    "papermill": {
     "duration": 0.025232,
     "end_time": "2023-01-28T07:55:31.296498",
     "exception": false,
     "start_time": "2023-01-28T07:55:31.271266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# y = df['Class']\n",
    "# df = df.drop(['id','Class'], axis=1)\n",
    "\n",
    "# df[df.columns] = scaler.fit_transform(df[df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e0ad333",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T07:55:31.328335Z",
     "iopub.status.busy": "2023-01-28T07:55:31.327911Z",
     "iopub.status.idle": "2023-01-28T07:55:33.146759Z",
     "shell.execute_reply": "2023-01-28T07:55:33.145453Z"
    },
    "papermill": {
     "duration": 1.838069,
     "end_time": "2023-01-28T07:55:33.149628",
     "exception": false,
     "start_time": "2023-01-28T07:55:31.311559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "rscale = RobustScaler()\n",
    "\n",
    "y = df['Class']\n",
    "df = df.drop(['id','Class'], axis=1)\n",
    "\n",
    "# df['Amount']=rscale.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "# df['Time']=rscale.fit_transform(df['Time'].values.reshape(-1,1))\n",
    "\n",
    "df[df.columns] = rscale.fit_transform(df[df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da4a1a88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T07:55:33.182294Z",
     "iopub.status.busy": "2023-01-28T07:55:33.181196Z",
     "iopub.status.idle": "2023-01-28T07:55:33.371699Z",
     "shell.execute_reply": "2023-01-28T07:55:33.370432Z"
    },
    "papermill": {
     "duration": 0.209407,
     "end_time": "2023-01-28T07:55:33.374418",
     "exception": false,
     "start_time": "2023-01-28T07:55:33.165011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>V_Sum</th>\n",
       "      <th>V_Min</th>\n",
       "      <th>V_Max</th>\n",
       "      <th>V_Avg</th>\n",
       "      <th>V_Std</th>\n",
       "      <th>V_Pos</th>\n",
       "      <th>V_Neg</th>\n",
       "      <th>V_Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.008662</td>\n",
       "      <td>0.891381</td>\n",
       "      <td>-0.125143</td>\n",
       "      <td>-0.700428</td>\n",
       "      <td>0.307221</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>-0.835775</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>-0.610947</td>\n",
       "      <td>0.666656</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.709796</td>\n",
       "      <td>0.502942</td>\n",
       "      <td>0.268731</td>\n",
       "      <td>-0.709796</td>\n",
       "      <td>-0.449470</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.180941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.008662</td>\n",
       "      <td>0.856978</td>\n",
       "      <td>-0.908666</td>\n",
       "      <td>-0.375086</td>\n",
       "      <td>-0.508814</td>\n",
       "      <td>-0.801136</td>\n",
       "      <td>-0.027915</td>\n",
       "      <td>-0.900964</td>\n",
       "      <td>-0.012667</td>\n",
       "      <td>-0.021900</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.430501</td>\n",
       "      <td>0.459923</td>\n",
       "      <td>0.179102</td>\n",
       "      <td>-0.430501</td>\n",
       "      <td>-0.146562</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-0.202530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.008662</td>\n",
       "      <td>-0.012076</td>\n",
       "      <td>0.667096</td>\n",
       "      <td>-0.218062</td>\n",
       "      <td>-0.222138</td>\n",
       "      <td>0.532603</td>\n",
       "      <td>-0.645014</td>\n",
       "      <td>0.824740</td>\n",
       "      <td>-0.270132</td>\n",
       "      <td>0.032985</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.524849</td>\n",
       "      <td>0.737101</td>\n",
       "      <td>-1.001244</td>\n",
       "      <td>-0.524849</td>\n",
       "      <td>-0.822400</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.983237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.008662</td>\n",
       "      <td>0.848240</td>\n",
       "      <td>-0.163936</td>\n",
       "      <td>-0.661789</td>\n",
       "      <td>0.124512</td>\n",
       "      <td>-0.125138</td>\n",
       "      <td>-0.352995</td>\n",
       "      <td>-0.079350</td>\n",
       "      <td>-0.175867</td>\n",
       "      <td>0.782772</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.233557</td>\n",
       "      <td>0.191832</td>\n",
       "      <td>0.156336</td>\n",
       "      <td>-0.233557</td>\n",
       "      <td>-0.476091</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-0.056709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.008662</td>\n",
       "      <td>0.413665</td>\n",
       "      <td>-0.154768</td>\n",
       "      <td>0.535149</td>\n",
       "      <td>0.825943</td>\n",
       "      <td>-0.439063</td>\n",
       "      <td>1.150352</td>\n",
       "      <td>-0.821865</td>\n",
       "      <td>0.977309</td>\n",
       "      <td>0.626673</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.928013</td>\n",
       "      <td>0.789572</td>\n",
       "      <td>-0.541977</td>\n",
       "      <td>0.928013</td>\n",
       "      <td>-0.470722</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.773793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146082</th>\n",
       "      <td>1.088941</td>\n",
       "      <td>-0.355348</td>\n",
       "      <td>-0.469970</td>\n",
       "      <td>0.288081</td>\n",
       "      <td>-0.296301</td>\n",
       "      <td>0.683361</td>\n",
       "      <td>-0.129952</td>\n",
       "      <td>0.137997</td>\n",
       "      <td>0.024995</td>\n",
       "      <td>0.631654</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.174076</td>\n",
       "      <td>-0.468049</td>\n",
       "      <td>-1.161062</td>\n",
       "      <td>-1.174076</td>\n",
       "      <td>-0.450348</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.357804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146083</th>\n",
       "      <td>1.088941</td>\n",
       "      <td>-0.098842</td>\n",
       "      <td>0.497589</td>\n",
       "      <td>0.079313</td>\n",
       "      <td>-0.318446</td>\n",
       "      <td>0.569516</td>\n",
       "      <td>-0.020947</td>\n",
       "      <td>0.631111</td>\n",
       "      <td>-0.243084</td>\n",
       "      <td>0.144488</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.467728</td>\n",
       "      <td>0.587503</td>\n",
       "      <td>-0.668498</td>\n",
       "      <td>0.467728</td>\n",
       "      <td>-0.682613</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.721107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146084</th>\n",
       "      <td>1.088941</td>\n",
       "      <td>-0.731751</td>\n",
       "      <td>1.201309</td>\n",
       "      <td>0.191020</td>\n",
       "      <td>0.275213</td>\n",
       "      <td>0.077212</td>\n",
       "      <td>0.278027</td>\n",
       "      <td>0.492591</td>\n",
       "      <td>-0.222657</td>\n",
       "      <td>0.334990</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.448856</td>\n",
       "      <td>0.209681</td>\n",
       "      <td>-0.093557</td>\n",
       "      <td>1.448856</td>\n",
       "      <td>-0.313379</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-0.197970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146085</th>\n",
       "      <td>1.088953</td>\n",
       "      <td>-0.914950</td>\n",
       "      <td>-0.142920</td>\n",
       "      <td>-0.063985</td>\n",
       "      <td>-1.140743</td>\n",
       "      <td>-1.263569</td>\n",
       "      <td>0.822157</td>\n",
       "      <td>0.853943</td>\n",
       "      <td>-0.508402</td>\n",
       "      <td>-0.382416</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.586508</td>\n",
       "      <td>-0.232731</td>\n",
       "      <td>-0.555834</td>\n",
       "      <td>-1.586508</td>\n",
       "      <td>0.370825</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.179565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146086</th>\n",
       "      <td>1.088953</td>\n",
       "      <td>0.884164</td>\n",
       "      <td>-1.063830</td>\n",
       "      <td>-1.128432</td>\n",
       "      <td>-1.133467</td>\n",
       "      <td>0.900205</td>\n",
       "      <td>3.311247</td>\n",
       "      <td>-1.370886</td>\n",
       "      <td>1.442732</td>\n",
       "      <td>0.029028</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.637668</td>\n",
       "      <td>-0.276464</td>\n",
       "      <td>2.093496</td>\n",
       "      <td>0.637668</td>\n",
       "      <td>1.257685</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>1.232453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>650023 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0      -1.008662  0.891381 -0.125143 -0.700428  0.307221 -0.108300 -0.835775   \n",
       "1      -1.008662  0.856978 -0.908666 -0.375086 -0.508814 -0.801136 -0.027915   \n",
       "2      -1.008662 -0.012076  0.667096 -0.218062 -0.222138  0.532603 -0.645014   \n",
       "3      -1.008662  0.848240 -0.163936 -0.661789  0.124512 -0.125138 -0.352995   \n",
       "4      -1.008662  0.413665 -0.154768  0.535149  0.825943 -0.439063  1.150352   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "146082  1.088941 -0.355348 -0.469970  0.288081 -0.296301  0.683361 -0.129952   \n",
       "146083  1.088941 -0.098842  0.497589  0.079313 -0.318446  0.569516 -0.020947   \n",
       "146084  1.088941 -0.731751  1.201309  0.191020  0.275213  0.077212  0.278027   \n",
       "146085  1.088953 -0.914950 -0.142920 -0.063985 -1.140743 -1.263569  0.822157   \n",
       "146086  1.088953  0.884164 -1.063830 -1.128432 -1.133467  0.900205  3.311247   \n",
       "\n",
       "              V7        V8        V9  ...   hour  day     V_Sum     V_Min  \\\n",
       "0       0.093900 -0.610947  0.666656  ... -1.875  0.0 -0.709796  0.502942   \n",
       "1      -0.900964 -0.012667 -0.021900  ... -1.875  0.0 -0.430501  0.459923   \n",
       "2       0.824740 -0.270132  0.032985  ... -1.875  0.0 -0.524849  0.737101   \n",
       "3      -0.079350 -0.175867  0.782772  ... -1.875  0.0 -0.233557  0.191832   \n",
       "4      -0.821865  0.977309  0.626673  ... -1.875  0.0  0.928013  0.789572   \n",
       "...          ...       ...       ...  ...    ...  ...       ...       ...   \n",
       "146082  0.137997  0.024995  0.631654  ...  1.000  1.0 -1.174076 -0.468049   \n",
       "146083  0.631111 -0.243084  0.144488  ...  1.000  1.0  0.467728  0.587503   \n",
       "146084  0.492591 -0.222657  0.334990  ...  1.000  1.0  1.448856  0.209681   \n",
       "146085  0.853943 -0.508402 -0.382416  ...  1.000  1.0 -1.586508 -0.232731   \n",
       "146086 -1.370886  1.442732  0.029028  ...  1.000  1.0  0.637668 -0.276464   \n",
       "\n",
       "           V_Max     V_Avg     V_Std  V_Pos  V_Neg   V_Range  \n",
       "0       0.268731 -0.709796 -0.449470  -0.75   0.75 -0.180941  \n",
       "1       0.179102 -0.430501 -0.146562  -1.25   1.25 -0.202530  \n",
       "2      -1.001244 -0.524849 -0.822400  -0.75   0.75 -0.983237  \n",
       "3       0.156336 -0.233557 -0.476091  -1.25   1.25 -0.056709  \n",
       "4      -0.541977  0.928013 -0.470722   0.50  -0.50 -0.773793  \n",
       "...          ...       ...       ...    ...    ...       ...  \n",
       "146082 -1.161062 -1.174076 -0.450348  -0.25   0.25 -0.357804  \n",
       "146083 -0.668498  0.467728 -0.682613   0.25  -0.25 -0.721107  \n",
       "146084 -0.093557  1.448856 -0.313379   1.25  -1.25 -0.197970  \n",
       "146085 -0.555834 -1.586508  0.370825  -1.00   1.00 -0.179565  \n",
       "146086  2.093496  0.637668  1.257685   0.50  -0.50  1.232453  \n",
       "\n",
       "[650023 rows x 41 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f63ce49",
   "metadata": {
    "papermill": {
     "duration": 0.015326,
     "end_time": "2023-01-28T07:55:33.405858",
     "exception": false,
     "start_time": "2023-01-28T07:55:33.390532",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Oversampling/undersampling idea from this amazing notebook:\n",
    "https://www.kaggle.com/code/vaidyaprasad84/ps3-e4-eda-sampling-ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8b32572",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T07:55:33.439046Z",
     "iopub.status.busy": "2023-01-28T07:55:33.438597Z",
     "iopub.status.idle": "2023-01-28T07:55:33.773548Z",
     "shell.execute_reply": "2023-01-28T07:55:33.772371Z"
    },
    "papermill": {
     "duration": 0.354932,
     "end_time": "2023-01-28T07:55:33.776437",
     "exception": false,
     "start_time": "2023-01-28T07:55:33.421505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = df.iloc[:-len(test_df),:]\n",
    "train_df['Class'] = y[:-len(test_df)]\n",
    "test_df = df.iloc[-len(test_df):,:].reset_index(drop=True)\n",
    "\n",
    "oversample = train_df[train_df['Class']==1]\n",
    "undersample = train_df[train_df['Class']==0]\n",
    "\n",
    "X = train_df.drop(['Class'], axis=1)\n",
    "y = train_df.Class\n",
    "X_test = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b632356",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T07:55:33.809461Z",
     "iopub.status.busy": "2023-01-28T07:55:33.809031Z",
     "iopub.status.idle": "2023-01-28T07:55:33.813941Z",
     "shell.execute_reply": "2023-01-28T07:55:33.812435Z"
    },
    "papermill": {
     "duration": 0.023802,
     "end_time": "2023-01-28T07:55:33.816109",
     "exception": false,
     "start_time": "2023-01-28T07:55:33.792307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# oversample1 = oversample[:200]\n",
    "# undersample1 = undersample[:100000]\n",
    "\n",
    "# oversample = oversample[200:]\n",
    "# undersample = undersample[100000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4e183fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T07:55:33.848976Z",
     "iopub.status.busy": "2023-01-28T07:55:33.848157Z",
     "iopub.status.idle": "2023-01-28T07:55:33.853292Z",
     "shell.execute_reply": "2023-01-28T07:55:33.852091Z"
    },
    "papermill": {
     "duration": 0.024231,
     "end_time": "2023-01-28T07:55:33.855712",
     "exception": false,
     "start_time": "2023-01-28T07:55:33.831481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X1 = X[:50000]\n",
    "# y1 = y[:50000]\n",
    "# X = X[50000:]\n",
    "# y = y[50000:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a225718",
   "metadata": {
    "papermill": {
     "duration": 0.015756,
     "end_time": "2023-01-28T07:55:33.886860",
     "exception": false,
     "start_time": "2023-01-28T07:55:33.871104",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**CatBoost regression model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2da7d1f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T07:55:33.919635Z",
     "iopub.status.busy": "2023-01-28T07:55:33.919180Z",
     "iopub.status.idle": "2023-01-28T07:55:33.925673Z",
     "shell.execute_reply": "2023-01-28T07:55:33.924442Z"
    },
    "papermill": {
     "duration": 0.025896,
     "end_time": "2023-01-28T07:55:33.928126",
     "exception": false,
     "start_time": "2023-01-28T07:55:33.902230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# import catboost\n",
    "# from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# def catboost_objective(trial):\n",
    "#     learning_rate = trial.suggest_float('learning_rate', 0, 0.3)\n",
    "#     depth = trial.suggest_int('depth', 3, 10)\n",
    "# #     n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "# #     subsample = trial.suggest_float('subsample', 0, 1)\n",
    "# #     l2_leaf_reg = trial.suggest_int('l2_leaf_reg', 1, 100)\n",
    "# #     min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 100)\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    \n",
    "#     model = catboost.CatBoostRegressor(\n",
    "#                 random_seed = 1234,             \n",
    "# #                 iterations = 5000,\n",
    "# #                 early_stopping_rounds = 1000,\n",
    "# #                 use_best_model = True,\n",
    "#                 eval_metric = 'RMSE',\n",
    "#                 verbose = 5000,\n",
    "    \n",
    "#                  depth = depth, \n",
    "#                  learning_rate = learning_rate, \n",
    "#                  rsm = 0.5,\n",
    "#                  subsample = 0.931, \n",
    "#                  l2_leaf_reg = 69,\n",
    "#                  min_data_in_leaf = 20,\n",
    "#                  random_strength = 0.175,\n",
    "#     )\n",
    "    \n",
    "#     model.fit(X_train, y_train)  \n",
    "\n",
    "# #     kf = KFold(n_splits= 5)\n",
    "# #     cv_score = cross_val_score(model, X, y, scoring= 'roc_auc', cv= kf)\n",
    "#     return roc_auc_score(y_test, model.predict(X_test))\n",
    "\n",
    "# study = optuna.create_study(direction= 'maximize')\n",
    "# study.optimize(catboost_objective, n_trials= 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65e1eda2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T07:55:33.961540Z",
     "iopub.status.busy": "2023-01-28T07:55:33.961081Z",
     "iopub.status.idle": "2023-01-28T07:55:33.965950Z",
     "shell.execute_reply": "2023-01-28T07:55:33.964756Z"
    },
    "papermill": {
     "duration": 0.02466,
     "end_time": "2023-01-28T07:55:33.968512",
     "exception": false,
     "start_time": "2023-01-28T07:55:33.943852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2324ef87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T07:55:34.002144Z",
     "iopub.status.busy": "2023-01-28T07:55:34.001699Z",
     "iopub.status.idle": "2023-01-28T07:57:58.921889Z",
     "shell.execute_reply": "2023-01-28T07:57:58.920919Z"
    },
    "papermill": {
     "duration": 144.940449,
     "end_time": "2023-01-28T07:57:58.924786",
     "exception": false,
     "start_time": "2023-01-28T07:55:33.984337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import catboost\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "n_folds = 2\n",
    "repeats = 30\n",
    "sample_size = 150000 # 200 000\n",
    "\n",
    "MAX_ITER = 15000\n",
    "PATIENCE = 1000\n",
    "DISPLAY_FREQ = 100\n",
    "\n",
    "modelsCB = []\n",
    "predsCB = []\n",
    "\n",
    "# k_fold = StratifiedKFold(n_splits=n_folds, random_state=42, shuffle=True)\n",
    "k_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=repeats, random_state=42) \n",
    "\n",
    "MODEL_PARAMS = {\n",
    "                'random_seed': 1234,             \n",
    "                'iterations': MAX_ITER,\n",
    "                'early_stopping_rounds': PATIENCE,\n",
    "#                 'use_best_model': True,\n",
    "                'eval_metric': 'RMSE',\n",
    "                'verbose': 1000,\n",
    "    \n",
    "                 'depth': 7, #3, \n",
    "                 'learning_rate': 0.1177165005048142, #0.01177165005048142, #0.2238051305181816,\n",
    "                 'rsm': 0.5,\n",
    "                 'subsample': 0.931, \n",
    "                 'l2_leaf_reg': 69, \n",
    "                 'min_data_in_leaf': 20, \n",
    "                 'random_strength': 0.175,\n",
    "               }\n",
    "\n",
    "catboost_params = {'n_estimators': 500,\n",
    "                   'learning_rate': 0.03, \n",
    "                   'one_hot_max_size': 12,\n",
    "                   'depth': 4,\n",
    "                   'l2_leaf_reg': 0.014,\n",
    "                   'colsample_bylevel': 0.06,\n",
    "                   'min_data_in_leaf': 12,\n",
    "                   'boosting_type': 'Plain',\n",
    "                   'bootstrap_type': 'Bernoulli',\n",
    "                   'verbose': False}\n",
    "\n",
    "\n",
    "# for train_index, test_index in k_fold.split(X, y):\n",
    "#     X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "# #     model = catboost.CatBoostClassifier(**MODEL_PARAMS)\n",
    "#     model = catboost.CatBoostRegressor(**MODEL_PARAMS)\n",
    "    \n",
    "#     model.fit(X=X_train, y=y_train,\n",
    "#           eval_set=[(X_valid, y_valid)],\n",
    "#           early_stopping_rounds = PATIENCE,\n",
    "# #           metric_period = DISPLAY_FREQ\n",
    "#          )\n",
    "#     modelsCB.append(model)\n",
    "#     predsCB.append(model.predict(X_test))\n",
    "    \n",
    "for i in range(repeats):\n",
    "    sample = undersample.sample(n=sample_size)\n",
    "    merged = pd.concat([oversample,sample])\n",
    "    X = merged.drop('Class', axis=1)\n",
    "    y = merged['Class']\n",
    "    model = catboost.CatBoostRegressor(**catboost_params)\n",
    "    model.fit(X,y,\n",
    "             early_stopping_rounds = PATIENCE,)\n",
    "    modelsCB.append(model)\n",
    "    predsCB.append(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67097202",
   "metadata": {
    "papermill": {
     "duration": 0.015046,
     "end_time": "2023-01-28T07:57:58.956033",
     "exception": false,
     "start_time": "2023-01-28T07:57:58.940987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**CatBoost classifier model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95c0889b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T07:57:58.989009Z",
     "iopub.status.busy": "2023-01-28T07:57:58.987869Z",
     "iopub.status.idle": "2023-01-28T07:57:58.993850Z",
     "shell.execute_reply": "2023-01-28T07:57:58.992889Z"
    },
    "papermill": {
     "duration": 0.025279,
     "end_time": "2023-01-28T07:57:58.996468",
     "exception": false,
     "start_time": "2023-01-28T07:57:58.971189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# import catboost\n",
    "# from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# def catboost_cl_objective(trial):\n",
    "#     learning_rate = trial.suggest_float('learning_rate', 0, 0.3)\n",
    "#     depth = trial.suggest_int('depth', 3, 10)\n",
    "# #     n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "# #     subsample = trial.suggest_float('subsample', 0, 1)\n",
    "# #     l2_leaf_reg = trial.suggest_int('l2_leaf_reg', 1, 100)\n",
    "# #     min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 100)\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    \n",
    "#     model = catboost.CatBoostClassifier(\n",
    "#                 random_seed = 1234,             \n",
    "# #                 iterations = 5000,\n",
    "# #                 early_stopping_rounds = 1000,\n",
    "# #                 use_best_model = True,\n",
    "#                 eval_metric = 'AUC',\n",
    "#                 verbose = 5000,\n",
    "    \n",
    "#                  depth = depth, \n",
    "#                  learning_rate = learning_rate, \n",
    "#                  rsm = 0.5,\n",
    "#                  subsample = 0.931, \n",
    "#                  l2_leaf_reg = 69,\n",
    "#                  min_data_in_leaf = 20,\n",
    "#                  random_strength = 0.175,\n",
    "#     )\n",
    "    \n",
    "#     model.fit(X_train, y_train)  \n",
    "\n",
    "# #     kf = KFold(n_splits= 5)\n",
    "# #     cv_score = cross_val_score(model, X, y, scoring= 'roc_auc', cv= kf)\n",
    "#     return roc_auc_score(y_test, model.predict(X_test))\n",
    "\n",
    "# study = optuna.create_study(direction= 'maximize')\n",
    "# study.optimize(catboost_cl_objective, n_trials= 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e172a9f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T07:57:59.030088Z",
     "iopub.status.busy": "2023-01-28T07:57:59.029681Z",
     "iopub.status.idle": "2023-01-28T07:57:59.034530Z",
     "shell.execute_reply": "2023-01-28T07:57:59.033239Z"
    },
    "papermill": {
     "duration": 0.02431,
     "end_time": "2023-01-28T07:57:59.036903",
     "exception": false,
     "start_time": "2023-01-28T07:57:59.012593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1451db88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T07:57:59.069976Z",
     "iopub.status.busy": "2023-01-28T07:57:59.069090Z",
     "iopub.status.idle": "2023-01-28T08:02:06.691821Z",
     "shell.execute_reply": "2023-01-28T08:02:06.690169Z"
    },
    "papermill": {
     "duration": 247.643056,
     "end_time": "2023-01-28T08:02:06.695290",
     "exception": false,
     "start_time": "2023-01-28T07:57:59.052234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_ITER = 15000\n",
    "PATIENCE = 1000\n",
    "DISPLAY_FREQ = 100\n",
    "\n",
    "modelsCBC = []\n",
    "predsCBC = []\n",
    "\n",
    "# k_fold = StratifiedKFold(n_splits=n_folds, random_state=42, shuffle=True)\n",
    "k_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=repeats, random_state=42) \n",
    "\n",
    "MODEL_PARAMS = {\n",
    "                'random_seed': 1234,             \n",
    "                'iterations': MAX_ITER,\n",
    "                'early_stopping_rounds': PATIENCE,\n",
    "#                 'use_best_model': True,\n",
    "                'eval_metric': 'AUC',\n",
    "#                 'eval_metric': 'RMSE',\n",
    "                'verbose': 1000,\n",
    "    \n",
    "                 'depth': 6, #3, \n",
    "                 'learning_rate': 0.08989547995455076, #0.2238051305181816, \n",
    "                 'rsm': 0.5,\n",
    "                 'subsample': 0.931, \n",
    "                 'l2_leaf_reg': 69, \n",
    "                 'min_data_in_leaf': 20, \n",
    "                 'random_strength': 0.175,\n",
    "               }\n",
    "catboost_params = {'n_estimators': 500,\n",
    "                   'learning_rate': 0.03, \n",
    "                   'one_hot_max_size': 12,\n",
    "                   'depth': 4,\n",
    "                   'l2_leaf_reg': 0.014,\n",
    "                   'colsample_bylevel': 0.06,\n",
    "                   'min_data_in_leaf': 12,\n",
    "                   'boosting_type': 'Plain',\n",
    "                   'bootstrap_type': 'Bernoulli',\n",
    "                   'verbose': False}\n",
    "\n",
    "# for train_index, test_index in k_fold.split(X, y):\n",
    "#     X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "#     model = catboost.CatBoostClassifier(**MODEL_PARAMS)\n",
    "# #     model = catboost.CatBoostRegressor(**MODEL_PARAMS)\n",
    "    \n",
    "#     model.fit(X=X_train, y=y_train,\n",
    "#           eval_set=[(X_valid, y_valid)],\n",
    "#           early_stopping_rounds = PATIENCE,\n",
    "# #           metric_period = DISPLAY_FREQ\n",
    "#          )\n",
    "#     modelsCBC.append(model)\n",
    "#     predsCBC.append(model.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "for i in range(repeats):\n",
    "    sample = undersample.sample(n=sample_size)\n",
    "    merged = pd.concat([oversample,sample])\n",
    "    X = merged.drop('Class', axis=1)\n",
    "    y = merged['Class']\n",
    "    model = catboost.CatBoostClassifier(**catboost_params)\n",
    "    model.fit(X,y,\n",
    "             early_stopping_rounds = PATIENCE,)\n",
    "    modelsCBC.append(model)\n",
    "    predsCBC.append(model.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc09df4f",
   "metadata": {
    "papermill": {
     "duration": 0.01619,
     "end_time": "2023-01-28T08:02:06.727909",
     "exception": false,
     "start_time": "2023-01-28T08:02:06.711719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**XGBoost regression model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62d5cd0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:02:06.762705Z",
     "iopub.status.busy": "2023-01-28T08:02:06.762271Z",
     "iopub.status.idle": "2023-01-28T08:02:06.769670Z",
     "shell.execute_reply": "2023-01-28T08:02:06.768017Z"
    },
    "papermill": {
     "duration": 0.028992,
     "end_time": "2023-01-28T08:02:06.772707",
     "exception": false,
     "start_time": "2023-01-28T08:02:06.743715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# import catboost\n",
    "# from xgboost import XGBClassifier, XGBRegressor\n",
    "# from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# def xgboost_objective(trial):\n",
    "#     learning_rate = trial.suggest_float('learning_rate', 0, 0.3)\n",
    "#     depth = trial.suggest_int('depth', 3, 10)\n",
    "# #     n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "# #     subsample = trial.suggest_float('subsample', 0, 1)\n",
    "# #     l2_leaf_reg = trial.suggest_int('l2_leaf_reg', 1, 100)\n",
    "# #     min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 100)\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    \n",
    "#     model = XGBRegressor(\n",
    "#                 n_estimators  = 2145,\n",
    "#               min_child_weight = 96,\n",
    "#               max_depth = depth,\n",
    "#               learning_rate = learning_rate,\n",
    "#               subsample = 0.95,\n",
    "#               colsample_bytree = 0.95,\n",
    "#               reg_lambda = 1.50,\n",
    "#               reg_alpha = 1.50,\n",
    "#               gamma = 1.50,\n",
    "#               max_bin = 512,\n",
    "#               random_state = 42,\n",
    "# #               'objective'        : 'binary:logistic',\n",
    "# #               early_stopping_rounds = 200,\n",
    "#               tree_method = 'hist',\n",
    "#               eval_metric = 'rmse',\n",
    "#     )\n",
    "    \n",
    "#     model.fit(X_train, y_train)  \n",
    "\n",
    "# #     kf = KFold(n_splits= 5)\n",
    "# #     cv_score = cross_val_score(model, X, y, scoring= 'roc_auc', cv= kf)\n",
    "#     return roc_auc_score(y_test, model.predict(X_test))\n",
    "\n",
    "# study = optuna.create_study(direction= 'maximize')\n",
    "# study.optimize(xgboost_objective, n_trials= 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60dbdac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:02:06.808668Z",
     "iopub.status.busy": "2023-01-28T08:02:06.807933Z",
     "iopub.status.idle": "2023-01-28T08:02:06.813565Z",
     "shell.execute_reply": "2023-01-28T08:02:06.811900Z"
    },
    "papermill": {
     "duration": 0.027888,
     "end_time": "2023-01-28T08:02:06.816994",
     "exception": false,
     "start_time": "2023-01-28T08:02:06.789106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "078a11f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:02:06.853151Z",
     "iopub.status.busy": "2023-01-28T08:02:06.852628Z",
     "iopub.status.idle": "2023-01-28T08:15:44.579775Z",
     "shell.execute_reply": "2023-01-28T08:15:44.578474Z"
    },
    "papermill": {
     "duration": 817.749708,
     "end_time": "2023-01-28T08:15:44.583785",
     "exception": false,
     "start_time": "2023-01-28T08:02:06.834077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "# k_fold = StratifiedKFold(n_splits=n_folds, random_state=42, shuffle=True)\n",
    "k_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=repeats, random_state=42) \n",
    "\n",
    "modelsXB = []\n",
    "predsXB = []\n",
    "\n",
    "PATIENCE = 200\n",
    "\n",
    "# MODEL_PARAMS = {       'n_estimators': 5000, \n",
    "#                        'learning_rate': 0.04625397031701272, #0.04625397031701272, 0.06733333333333334\n",
    "#                        'max_depth': 3, #3, 29\n",
    "#                        'colsample_bytree': 0.9, #0.12954517333371557, #0.9, #0.9, 0.99\n",
    "#                        'subsample': 1, #0.7426054009856451, #1, #1, 0.99\n",
    "# #                        'min_child_weight': 12, #\n",
    "# #                        'gamma': 0.11888888888888888, #\n",
    "#                        'reg_lambda': 20, #55, #20,\n",
    "# #                        'eval_metric': 'auc',\n",
    "#                        'eval_metric': 'rmse',\n",
    "#                        'early_stopping_rounds': PATIENCE,\n",
    "# #                        'tree_method': 'gpu_hist',\n",
    "#                        'seed': 1\n",
    "# }\n",
    "\n",
    "MODEL_PARAMS = {'n_estimators'     : 2145,\n",
    "              'min_child_weight' : 96,\n",
    "              'max_depth'        : 8, #7,\n",
    "              'learning_rate'    : 0.04791309460309468, #0.18,\n",
    "              'subsample'        : 0.95,\n",
    "              'colsample_bytree' : 0.95,\n",
    "              'reg_lambda'       : 1.50,\n",
    "              'reg_alpha'        : 1.50,\n",
    "              'gamma'            : 1.50,\n",
    "              'max_bin'          : 512,\n",
    "              'random_state'     : 42,\n",
    "#               'objective'        : 'binary:logistic',\n",
    "#               'early_stopping_rounds': PATIENCE,\n",
    "              'tree_method'      : 'hist',\n",
    "              'eval_metric'      : 'rmse', #'auc'\n",
    "             } \n",
    "\n",
    "xgb_params = {'n_estimators'     : 2000,\n",
    "              'min_child_weight' : 96,\n",
    "              'max_depth'        : 7,\n",
    "              'learning_rate'    : 0.18,\n",
    "              'subsample'        : 0.95,\n",
    "              'colsample_bytree' : 0.95,\n",
    "              'reg_lambda'       : 1.50,\n",
    "              'reg_alpha'        : 1.50,\n",
    "              'gamma'            : 1.50,\n",
    "              'max_bin'          : 512,\n",
    "              'random_state'     : 42,\n",
    "              'objective'        : 'binary:logistic',\n",
    "              'tree_method'      : 'hist',\n",
    "              'eval_metric'      : 'rmse', #'auc'\n",
    "             }\n",
    "\n",
    "# for train_index, test_index in k_fold.split(X, y):\n",
    "#     X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "# #     model = XGBClassifier(**MODEL_PARAMS)\n",
    "#     model = XGBRegressor(**MODEL_PARAMS)\n",
    "    \n",
    "#     model.fit(X=X_train, y=y_train,\n",
    "#           eval_set=[(X_valid, y_valid)],\n",
    "# #           early_stopping_rounds = PATIENCE,\n",
    "#           verbose = 100\n",
    "#          )\n",
    "#     modelsXB.append(model)\n",
    "#     predsXB.append(model.predict(X_test))\n",
    "    \n",
    "for i in range(repeats):\n",
    "    sample = undersample.sample(n=sample_size)\n",
    "    merged = pd.concat([oversample,sample])\n",
    "    X = merged.drop('Class', axis=1)\n",
    "    y = merged['Class']\n",
    "    model = XGBRegressor(**xgb_params)\n",
    "    model.fit(X,y,verbose = 100,\n",
    "#              early_stopping_rounds = PATIENCE,\n",
    "             )\n",
    "    modelsXB.append(model)\n",
    "    predsXB.append(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192619cb",
   "metadata": {
    "papermill": {
     "duration": 0.016325,
     "end_time": "2023-01-28T08:15:44.619967",
     "exception": false,
     "start_time": "2023-01-28T08:15:44.603642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**XGBoost classifier model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee38a308",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:15:44.653584Z",
     "iopub.status.busy": "2023-01-28T08:15:44.653165Z",
     "iopub.status.idle": "2023-01-28T08:15:44.659690Z",
     "shell.execute_reply": "2023-01-28T08:15:44.658414Z"
    },
    "papermill": {
     "duration": 0.026179,
     "end_time": "2023-01-28T08:15:44.662132",
     "exception": false,
     "start_time": "2023-01-28T08:15:44.635953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# import catboost\n",
    "# from xgboost import XGBClassifier, XGBRegressor\n",
    "# from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# def xgboost_cl_objective(trial):\n",
    "#     learning_rate = trial.suggest_float('learning_rate', 0, 0.3)\n",
    "#     depth = trial.suggest_int('depth', 3, 10)\n",
    "# #     n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "# #     subsample = trial.suggest_float('subsample', 0, 1)\n",
    "# #     l2_leaf_reg = trial.suggest_int('l2_leaf_reg', 1, 100)\n",
    "# #     min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 100)\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    \n",
    "#     model = XGBClassifier(\n",
    "#                 n_estimators  = 2145,\n",
    "#               min_child_weight = 96,\n",
    "#               max_depth = depth,\n",
    "#               learning_rate = learning_rate,\n",
    "#               subsample = 0.95,\n",
    "#               colsample_bytree = 0.95,\n",
    "#               reg_lambda = 1.50,\n",
    "#               reg_alpha = 1.50,\n",
    "#               gamma = 1.50,\n",
    "#               max_bin = 512,\n",
    "#               random_state = 42,\n",
    "# #               'objective'        : 'binary:logistic',\n",
    "# #               early_stopping_rounds = 200,\n",
    "#               tree_method = 'hist',\n",
    "#               eval_metric = 'auc',\n",
    "#     )\n",
    "    \n",
    "#     model.fit(X_train, y_train)  \n",
    "\n",
    "# #     kf = KFold(n_splits= 5)\n",
    "# #     cv_score = cross_val_score(model, X, y, scoring= 'roc_auc', cv= kf)\n",
    "#     return roc_auc_score(y_test, model.predict(X_test))\n",
    "\n",
    "# study = optuna.create_study(direction= 'maximize')\n",
    "# study.optimize(xgboost_cl_objective, n_trials= 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dde15427",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:15:44.696036Z",
     "iopub.status.busy": "2023-01-28T08:15:44.695638Z",
     "iopub.status.idle": "2023-01-28T08:15:44.700134Z",
     "shell.execute_reply": "2023-01-28T08:15:44.698811Z"
    },
    "papermill": {
     "duration": 0.024892,
     "end_time": "2023-01-28T08:15:44.702648",
     "exception": false,
     "start_time": "2023-01-28T08:15:44.677756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de09e8b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:15:44.736901Z",
     "iopub.status.busy": "2023-01-28T08:15:44.736497Z",
     "iopub.status.idle": "2023-01-28T08:29:24.793512Z",
     "shell.execute_reply": "2023-01-28T08:29:24.792082Z"
    },
    "papermill": {
     "duration": 820.080033,
     "end_time": "2023-01-28T08:29:24.798870",
     "exception": false,
     "start_time": "2023-01-28T08:15:44.718837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "k_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=repeats, random_state=42) \n",
    "\n",
    "modelsXBC = []\n",
    "predsXBC = []\n",
    "\n",
    "PATIENCE = 200\n",
    "\n",
    "# MODEL_PARAMS = {       'n_estimators': 5000, \n",
    "#                        'learning_rate': 0.04625397031701272, #0.02910875107189472, #0.04625397031701272, 0.06733333333333334\n",
    "#                        'max_depth': 3, #4, #3, 29\n",
    "#                        'colsample_bytree': 0.9, #0.11912735505392935, #0.9, #0.9, 0.99\n",
    "#                        'subsample': 1, #0.7605555695727094, # 1, #1, 0.99\n",
    "# #                        'min_child_weight': 12, #\n",
    "# #                        'gamma': 0.11888888888888888, #\n",
    "#                        'reg_lambda': 20, #17, #20,\n",
    "#                        'eval_metric': 'auc',\n",
    "# #                        'eval_metric': 'rmse',\n",
    "#                        'early_stopping_rounds': PATIENCE,\n",
    "# #                        'tree_method': 'gpu_hist',\n",
    "#                        'seed': 1\n",
    "# }\n",
    "\n",
    "MODEL_PARAMS = {'n_estimators'     : 2145,\n",
    "              'min_child_weight' : 96,\n",
    "              'max_depth'        : 5, #7,\n",
    "              'learning_rate'    : 0.25242368703215484, #0.18,\n",
    "              'subsample'        : 0.95,\n",
    "              'colsample_bytree' : 0.95,\n",
    "              'reg_lambda'       : 1.50,\n",
    "              'reg_alpha'        : 1.50,\n",
    "              'gamma'            : 1.50,\n",
    "              'max_bin'          : 512,\n",
    "              'random_state'     : 42,\n",
    "              'objective'        : 'binary:logistic',\n",
    "#               'early_stopping_rounds': PATIENCE,\n",
    "              'tree_method'      : 'hist',\n",
    "              'eval_metric'      : 'auc'\n",
    "             }\n",
    "\n",
    "xgb_params = {'n_estimators'     : 2000,\n",
    "              'min_child_weight' : 96,\n",
    "              'max_depth'        : 7,\n",
    "              'learning_rate'    : 0.18,\n",
    "              'subsample'        : 0.95,\n",
    "              'colsample_bytree' : 0.95,\n",
    "              'reg_lambda'       : 1.50,\n",
    "              'reg_alpha'        : 1.50,\n",
    "              'gamma'            : 1.50,\n",
    "              'max_bin'          : 512,\n",
    "              'random_state'     : 42,\n",
    "              'objective'        : 'binary:logistic',\n",
    "              'tree_method'      : 'hist',\n",
    "              'eval_metric'      : 'auc'\n",
    "             }\n",
    "\n",
    "# for train_index, test_index in k_fold.split(X, y):\n",
    "#     X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "#     model = XGBClassifier(**MODEL_PARAMS)\n",
    "# #     model = XGBRegressor(**MODEL_PARAMS)\n",
    "    \n",
    "#     model.fit(X=X_train, y=y_train,\n",
    "#           eval_set=[(X_valid, y_valid)],\n",
    "# #           early_stopping_rounds = PATIENCE,\n",
    "#           verbose = 100\n",
    "#          )\n",
    "#     modelsXBC.append(model)\n",
    "#     predsXBC.append(model.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "for i in range(repeats):\n",
    "    sample = undersample.sample(n=sample_size)\n",
    "    merged = pd.concat([oversample,sample])\n",
    "    X = merged.drop('Class', axis=1)\n",
    "    y = merged['Class']\n",
    "    model = XGBClassifier(**xgb_params)\n",
    "    model.fit(X,y,verbose = 100,\n",
    "#              early_stopping_rounds = PATIENCE,\n",
    "             )\n",
    "    modelsXBC.append(model)\n",
    "    predsXBC.append(model.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75c351dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:29:24.835611Z",
     "iopub.status.busy": "2023-01-28T08:29:24.835161Z",
     "iopub.status.idle": "2023-01-28T08:30:52.805714Z",
     "shell.execute_reply": "2023-01-28T08:30:52.804163Z"
    },
    "papermill": {
     "duration": 87.991432,
     "end_time": "2023-01-28T08:30:52.808452",
     "exception": false,
     "start_time": "2023-01-28T08:29:24.817020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "\n",
    "k_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=repeats, random_state=42) \n",
    "\n",
    "modelsLBC = []\n",
    "predsLBC = []\n",
    "\n",
    "# PATIENCE = 200\n",
    "\n",
    "params={\n",
    "             'objective': 'binary',\n",
    "             'metric': 'auc',\n",
    "             'lambda_l1': 1.0050418664783436e-08, \n",
    "             'lambda_l2': 9.938606206413121,\n",
    "             'scale_pos_weight': 1, #param could be ignored\n",
    "             'num_leaves': 44,\n",
    "             'feature_fraction': 0.8247273276668773,\n",
    "             'bagging_fraction': 0.5842711778104962,\n",
    "             'bagging_freq': 6,\n",
    "             'min_data_in_leaf': 134,\n",
    "             'min_child_samples': 70,\n",
    "             'max_depth': 8,\n",
    "             'num_iterations': 400,\n",
    "             'learning_rate':0.05}\n",
    "\n",
    "lgbm_params = {'n_estimators': 500,\n",
    "                 'num_rounds': 274,\n",
    "                 'learning_rate': 0.1,\n",
    "                 'num_leaves': 195,\n",
    "                 'max_depth': 9,\n",
    "                 'min_data_in_leaf': 46,\n",
    "                 'lambda_l1': 0.01,\n",
    "                 'lambda_l2': 0.6,\n",
    "                 'min_gain_to_split': 1.42,\n",
    "                 'bagging_fraction': 0.45,\n",
    "                 'feature_fraction': 0.3,\n",
    "                 'verbose':-1}\n",
    "\n",
    "# for train_index, test_index in k_fold.split(X, y):\n",
    "#     X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "#     model = lgbm.LGBMClassifier(**params)\n",
    "# #     model = lgbm.LGBMRegressor(**MODEL_PARAMS)\n",
    "    \n",
    "#     model.fit(X=X_train, y=y_train,\n",
    "#           eval_set=[(X_valid, y_valid)],\n",
    "#           early_stopping_rounds = 50,\n",
    "#           verbose = 100\n",
    "#          )\n",
    "#     modelsLBC.append(model)\n",
    "#     predsLBC.append(model.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "for i in range(repeats):\n",
    "    sample = undersample.sample(n=sample_size)\n",
    "    merged = pd.concat([oversample,sample])\n",
    "    X = merged.drop('Class', axis=1)\n",
    "    y = merged['Class']\n",
    "    model = lgbm.LGBMClassifier(**lgbm_params)\n",
    "    model.fit(X=X,y=y,verbose = 100,\n",
    "#              early_stopping_rounds = PATIENCE,\n",
    "             )\n",
    "    modelsLBC.append(model)\n",
    "    predsLBC.append(model.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7cf047c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:30:52.848895Z",
     "iopub.status.busy": "2023-01-28T08:30:52.848471Z",
     "iopub.status.idle": "2023-01-28T08:31:42.017015Z",
     "shell.execute_reply": "2023-01-28T08:31:42.016039Z"
    },
    "papermill": {
     "duration": 49.190791,
     "end_time": "2023-01-28T08:31:42.019832",
     "exception": false,
     "start_time": "2023-01-28T08:30:52.829041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
      "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "\n",
    "k_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=repeats, random_state=42) \n",
    "\n",
    "modelsLB = []\n",
    "predsLB = []\n",
    "\n",
    "# PATIENCE = 200\n",
    "\n",
    "params={\n",
    "#              'objective': 'binary',\n",
    "             'metric': 'rmse',\n",
    "             'lambda_l1': 1.0050418664783436e-08, \n",
    "             'lambda_l2': 9.938606206413121,\n",
    "             'scale_pos_weight': 1, #param could be ignored\n",
    "             'num_leaves': 44,\n",
    "             'feature_fraction': 0.8247273276668773,\n",
    "             'bagging_fraction': 0.5842711778104962,\n",
    "             'bagging_freq': 6,\n",
    "             'min_data_in_leaf': 134,\n",
    "             'min_child_samples': 70,\n",
    "             'max_depth': 8,\n",
    "             'num_iterations': 400,\n",
    "             'learning_rate':0.05}\n",
    "\n",
    "lgbm_params = {'n_estimators': 500,\n",
    "                 'num_rounds': 274,\n",
    "                 'learning_rate': 0.1,\n",
    "                 'num_leaves': 195,\n",
    "                 'max_depth': 9,\n",
    "                 'min_data_in_leaf': 46,\n",
    "                 'lambda_l1': 0.01,\n",
    "                 'lambda_l2': 0.6,\n",
    "                 'min_gain_to_split': 1.42,\n",
    "                 'bagging_fraction': 0.45,\n",
    "                 'feature_fraction': 0.3,\n",
    "                 'verbose':-1}\n",
    "\n",
    "# for train_index, test_index in k_fold.split(X, y):\n",
    "#     X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "# #     model = lgbm.LGBMClassifier(**MODEL_PARAMS)\n",
    "#     model = lgbm.LGBMRegressor(**params)\n",
    "    \n",
    "#     model.fit(X=X_train, y=y_train,\n",
    "#           eval_set=[(X_valid, y_valid)],\n",
    "#           early_stopping_rounds = 50,\n",
    "#           verbose = 100\n",
    "#          )\n",
    "#     modelsLB.append(model)\n",
    "#     predsLB.append(model.predict(X_test))\n",
    "    \n",
    "for i in range(repeats):\n",
    "    sample = undersample.sample(n=sample_size)\n",
    "    merged = pd.concat([oversample,sample])\n",
    "    X = merged.drop('Class', axis=1)\n",
    "    y = merged['Class']\n",
    "    model = lgbm.LGBMRegressor(**lgbm_params)\n",
    "    model.fit(X=X,y=y,verbose = 100,\n",
    "#              early_stopping_rounds = PATIENCE,\n",
    "             )\n",
    "    modelsLB.append(model)\n",
    "    predsLB.append(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675260fe",
   "metadata": {
    "papermill": {
     "duration": 0.020275,
     "end_time": "2023-01-28T08:31:42.062468",
     "exception": false,
     "start_time": "2023-01-28T08:31:42.042193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Lasso linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb175aa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:31:42.105101Z",
     "iopub.status.busy": "2023-01-28T08:31:42.104695Z",
     "iopub.status.idle": "2023-01-28T08:31:56.738711Z",
     "shell.execute_reply": "2023-01-28T08:31:56.736276Z"
    },
    "papermill": {
     "duration": 14.660579,
     "end_time": "2023-01-28T08:31:56.743540",
     "exception": false,
     "start_time": "2023-01-28T08:31:42.082961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "\n",
    "# n_folds = 20\n",
    "# k_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=2*repeats, random_state=42) # 20\n",
    "\n",
    "modelsLR = []\n",
    "predsLR = []\n",
    "\n",
    "MODEL_PARAMS = {\n",
    "                       'precompute': \"auto\",\n",
    "                       'fit_intercept': True,\n",
    "                       'normalize': False,\n",
    "                       'max_iter': 10000,\n",
    "                       'verbose': False,\n",
    "                       'eps': 0.000001, #1e-04, #0.007267206407101401, #1e-04,\n",
    "                       'cv': 5, #6, #5,\n",
    "                       'n_alphas': 1000,\n",
    "                       'n_jobs': 8,\n",
    "                       'tol': 0.0001\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# for train_index, test_index in k_fold.split(X, y):\n",
    "#     X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "#     model = LassoCV(**MODEL_PARAMS)\n",
    "    \n",
    "#     model.fit(X=X_train, y=y_train,\n",
    "# #           eval_set=[(X_valid, y_valid)],\n",
    "#          )\n",
    "    \n",
    "#     modelsLR.append(model)\n",
    "#     predsLR.append(model.predict(X_test))\n",
    "    \n",
    "for i in range(repeats):\n",
    "    sample = undersample.sample(n=sample_size)\n",
    "    merged = pd.concat([oversample,sample])\n",
    "    X = merged.drop('Class', axis=1)\n",
    "    y = merged['Class']\n",
    "    model = Lasso(alpha=0.001)\n",
    "    model.fit(X,y,\n",
    "#              early_stopping_rounds = PATIENCE,\n",
    "             )\n",
    "    modelsLR.append(model)\n",
    "    predsLR.append(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1082fc7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:31:56.864708Z",
     "iopub.status.busy": "2023-01-28T08:31:56.864204Z",
     "iopub.status.idle": "2023-01-28T08:31:56.883336Z",
     "shell.execute_reply": "2023-01-28T08:31:56.882232Z"
    },
    "papermill": {
     "duration": 0.049864,
     "end_time": "2023-01-28T08:31:56.885947",
     "exception": false,
     "start_time": "2023-01-28T08:31:56.836083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-28 08:31:56,877]\u001b[0m A new study created in memory with name: no-name-f0d50087-d149-4034-a97f-a44d7d2f5237\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    " \n",
    "def coef_objective(trial):\n",
    "    a = trial.suggest_float('a', 0, 1)\n",
    "    b = trial.suggest_float('b', 0, 1)\n",
    "    c = trial.suggest_float('c', 0, 1)\n",
    "    d = trial.suggest_float('d', 0, 1)\n",
    "    e = trial.suggest_float('e', 0, 1)\n",
    "    f = trial.suggest_float('f', 0, 1)\n",
    "#     g = trial.suggest_float('g', 0, 1)\n",
    "        \n",
    "#     merged = pd.concat([oversample1,undersample1])\n",
    "#     X = merged.drop('Class', axis=1)\n",
    "#     y = merged['Class']\n",
    "\n",
    "#     X = X1\n",
    "#     y = y1\n",
    "    \n",
    "    preds_eval = []\n",
    "    for model in modelsCB:\n",
    "        preds_eval.append(model.predict(X))\n",
    "    \n",
    "    resCB = np.average(np.array(preds_eval),axis=0)\n",
    "\n",
    "    preds_eval = []\n",
    "    for model in modelsXB:\n",
    "        preds_eval.append(model.predict(X))\n",
    "    \n",
    "    resXB = np.average(np.array(preds_eval),axis=0)\n",
    "    \n",
    "    preds_eval = []\n",
    "    for model in modelsCBC:\n",
    "        preds_eval.append(model.predict_proba(X)[:, 1])\n",
    "    \n",
    "    resCBC = np.average(np.array(preds_eval),axis=0)\n",
    "    \n",
    "    preds_eval = []\n",
    "    for model in modelsXBC:\n",
    "        preds_eval.append(model.predict_proba(X)[:, 1])\n",
    "    \n",
    "    resXBC = np.average(np.array(preds_eval),axis=0)\n",
    "    \n",
    "    preds_eval = []\n",
    "    for model in modelsLBC:\n",
    "        preds_eval.append(model.predict_proba(X)[:, 1])\n",
    "    \n",
    "    resLBC = np.average(np.array(preds_eval),axis=0)\n",
    "    \n",
    "    preds_eval = []\n",
    "    for model in modelsLB:\n",
    "        preds_eval.append(model.predict(X))\n",
    "    \n",
    "    resLB = np.average(np.array(preds_eval),axis=0)\n",
    "\n",
    "\n",
    "#     preds_eval = []\n",
    "#     for model in modelsLR:\n",
    "#         preds_eval.append(model.predict(X))\n",
    "    \n",
    "#     resLR = np.average(np.array(preds_eval),axis=0)\n",
    "\n",
    "    res = roc_auc_score(y,\n",
    "                        (resCB * a + resXB * b + resCBC * c + resXBC * d + resLBC * e + \n",
    "                         resLB * f )/(a + b + c + d + e + f))\n",
    "\n",
    "    return res\n",
    "\n",
    "study = optuna.create_study(direction= 'maximize')\n",
    "# study.optimize(coef_objective, n_trials= 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e2fee27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:31:56.928060Z",
     "iopub.status.busy": "2023-01-28T08:31:56.927103Z",
     "iopub.status.idle": "2023-01-28T08:31:56.931996Z",
     "shell.execute_reply": "2023-01-28T08:31:56.931208Z"
    },
    "papermill": {
     "duration": 0.028065,
     "end_time": "2023-01-28T08:31:56.934126",
     "exception": false,
     "start_time": "2023-01-28T08:31:56.906061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8817b599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:31:56.976109Z",
     "iopub.status.busy": "2023-01-28T08:31:56.974894Z",
     "iopub.status.idle": "2023-01-28T08:31:56.980241Z",
     "shell.execute_reply": "2023-01-28T08:31:56.979473Z"
    },
    "papermill": {
     "duration": 0.028661,
     "end_time": "2023-01-28T08:31:56.982387",
     "exception": false,
     "start_time": "2023-01-28T08:31:56.953726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a = study.best_params['a']\n",
    "# b = study.best_params['b']\n",
    "# c = study.best_params['c']\n",
    "# d = study.best_params['d']\n",
    "# e = study.best_params['e']\n",
    "# f = study.best_params['f']\n",
    "# # g = study.best_params['g']\n",
    "\n",
    "# sum_coef = a + b + c + d + e + f\n",
    "# a = a / sum_coef\n",
    "# b = b / sum_coef\n",
    "# c = c / sum_coef\n",
    "# d = d / sum_coef\n",
    "# e = e / sum_coef\n",
    "# f = f / sum_coef\n",
    "# # g = g / sum_coef\n",
    "\n",
    "# a, b, c, d, e, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b3aafd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:31:57.023614Z",
     "iopub.status.busy": "2023-01-28T08:31:57.023179Z",
     "iopub.status.idle": "2023-01-28T08:31:57.027807Z",
     "shell.execute_reply": "2023-01-28T08:31:57.026692Z"
    },
    "papermill": {
     "duration": 0.028315,
     "end_time": "2023-01-28T08:31:57.030338",
     "exception": false,
     "start_time": "2023-01-28T08:31:57.002023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a = 0.3669557354589081\n",
    "# b = 0.337641198537538\n",
    "# c = 0.008900837188394609\n",
    "# d = 0.2447433523478509\n",
    "# e = 0.04175887646730838"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6df99fbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:31:57.073404Z",
     "iopub.status.busy": "2023-01-28T08:31:57.072996Z",
     "iopub.status.idle": "2023-01-28T08:31:57.077180Z",
     "shell.execute_reply": "2023-01-28T08:31:57.076073Z"
    },
    "papermill": {
     "duration": 0.029301,
     "end_time": "2023-01-28T08:31:57.079630",
     "exception": false,
     "start_time": "2023-01-28T08:31:57.050329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a = 0.14719373356287416\n",
    "# b = 0.21197835016639707\n",
    "# c = 0.5218752467435989\n",
    "# d = 0.11810079201731347\n",
    "# e = 0.0008518775098164659"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34d83236",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:31:57.122334Z",
     "iopub.status.busy": "2023-01-28T08:31:57.121893Z",
     "iopub.status.idle": "2023-01-28T08:31:57.126365Z",
     "shell.execute_reply": "2023-01-28T08:31:57.125243Z"
    },
    "papermill": {
     "duration": 0.028359,
     "end_time": "2023-01-28T08:31:57.128769",
     "exception": false,
     "start_time": "2023-01-28T08:31:57.100410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a = 0.013732712049429857\n",
    "# b = 0.11139158723935387\n",
    "# c = 0.7579975888425357\n",
    "# d = 0.11626614433593775\n",
    "# e = 0.0006119675327428372"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd737007",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:31:57.171273Z",
     "iopub.status.busy": "2023-01-28T08:31:57.170894Z",
     "iopub.status.idle": "2023-01-28T08:31:57.175308Z",
     "shell.execute_reply": "2023-01-28T08:31:57.174219Z"
    },
    "papermill": {
     "duration": 0.028568,
     "end_time": "2023-01-28T08:31:57.177622",
     "exception": false,
     "start_time": "2023-01-28T08:31:57.149054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a = 0.004924244009922518 + 0.011877491530298148\n",
    "# b = 0.3117566542173961\n",
    "# c = 0.10166065209557595\n",
    "# d = 0.0503241817163487\n",
    "# e = 0.4682759529883892\n",
    "# f = 0.051180823442069395\n",
    "# g = 0 #0.011877491530298148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49cb457d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:31:57.219662Z",
     "iopub.status.busy": "2023-01-28T08:31:57.218458Z",
     "iopub.status.idle": "2023-01-28T08:31:57.223338Z",
     "shell.execute_reply": "2023-01-28T08:31:57.222493Z"
    },
    "papermill": {
     "duration": 0.028192,
     "end_time": "2023-01-28T08:31:57.225392",
     "exception": false,
     "start_time": "2023-01-28T08:31:57.197200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a = 0.17\n",
    "# b = 0.16\n",
    "# c = 0.17\n",
    "# d = 0.17\n",
    "# e = 0.17\n",
    "# f = 0.16\n",
    "# g = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40f7e0bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:31:57.266634Z",
     "iopub.status.busy": "2023-01-28T08:31:57.265957Z",
     "iopub.status.idle": "2023-01-28T08:31:57.272060Z",
     "shell.execute_reply": "2023-01-28T08:31:57.271214Z"
    },
    "papermill": {
     "duration": 0.029533,
     "end_time": "2023-01-28T08:31:57.274555",
     "exception": false,
     "start_time": "2023-01-28T08:31:57.245022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a = 0.15\n",
    "# b = 0.14\n",
    "# c = 0.15\n",
    "# d = 0.14\n",
    "# e = 0.14\n",
    "# f = 0.14\n",
    "# g = 0.14\n",
    "\n",
    "# a = 0.13\n",
    "# b = 0.14\n",
    "# c = 0.2\n",
    "# d = 0.2\n",
    "# e = 0.2\n",
    "# f = 0.13\n",
    "# g = 0 \n",
    "\n",
    "# a = 0.2\n",
    "# b = 0.2\n",
    "# c = 0.13\n",
    "# d = 0.14\n",
    "# e = 0.13\n",
    "# f = 0.2\n",
    "# g = 0 \n",
    "\n",
    "# a = 0.23\n",
    "# b = 0.23\n",
    "# c = 0.1\n",
    "# d = 0.11\n",
    "# e = 0.1\n",
    "# f = 0.23\n",
    "# g = 0\n",
    "\n",
    "# 0.87022\n",
    "\n",
    "# a = 0.25\n",
    "# b = 0.25\n",
    "# c = 0.08\n",
    "# d = 0.09\n",
    "# e = 0.08\n",
    "# f = 0.25\n",
    "# g = 0\n",
    "\n",
    "# 0.86927\n",
    "\n",
    "# a = 0.22\n",
    "# b = 0.22\n",
    "# c = 0.11\n",
    "# d = 0.12\n",
    "# e = 0.11\n",
    "# f = 0.22\n",
    "# g = 0\n",
    "\n",
    "# 0.86997\n",
    "\n",
    "a = 0.24\n",
    "b = 0.24\n",
    "c = 0.09\n",
    "d = 0.10\n",
    "e = 0.09\n",
    "f = 0.24\n",
    "g = 0\n",
    "\n",
    "# 0.87044\n",
    "\n",
    "# a = 0.235\n",
    "# b = 0.235\n",
    "# c = 0.095\n",
    "# d = 0.105\n",
    "# e = 0.095\n",
    "# f = 0.235\n",
    "# g = 0\n",
    "\n",
    "# 0.86909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1395ae7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:31:57.317478Z",
     "iopub.status.busy": "2023-01-28T08:31:57.316738Z",
     "iopub.status.idle": "2023-01-28T08:31:57.320815Z",
     "shell.execute_reply": "2023-01-28T08:31:57.319888Z"
    },
    "papermill": {
     "duration": 0.02805,
     "end_time": "2023-01-28T08:31:57.322949",
     "exception": false,
     "start_time": "2023-01-28T08:31:57.294899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a = 0.008764460310928566\n",
    "# b = 0.2964161989525224\n",
    "# c = 0.19274616797827318\n",
    "# d = 0.3180908607731729\n",
    "# e = 0.18358232512438427\n",
    "# f = 0.00039998686071876055\n",
    "# g = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04bc2ca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:31:57.364525Z",
     "iopub.status.busy": "2023-01-28T08:31:57.364104Z",
     "iopub.status.idle": "2023-01-28T08:31:57.481648Z",
     "shell.execute_reply": "2023-01-28T08:31:57.479652Z"
    },
    "papermill": {
     "duration": 0.141932,
     "end_time": "2023-01-28T08:31:57.485063",
     "exception": false,
     "start_time": "2023-01-28T08:31:57.343131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predCB = np.average(np.array(predsCB),axis=0).clip(0,1)\n",
    "predXB = np.average(np.array(predsXB),axis=0).clip(0,1)\n",
    "predCBC = np.average(np.array(predsCBC),axis=0).clip(0,1)\n",
    "predXBC = np.average(np.array(predsXBC),axis=0).clip(0,1)\n",
    "predLBC = np.average(np.array(predsLBC),axis=0).clip(0,1)\n",
    "predLB = np.average(np.array(predsLB),axis=0).clip(0,1)\n",
    "predLR = np.average(np.array(predsLR),axis=0).clip(0,1)\n",
    "\n",
    "pred = predCB * a + predXB * b + predCBC * c + predXBC * d + predLBC * e + predLB * f + predLR * g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8388c87c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:31:57.545919Z",
     "iopub.status.busy": "2023-01-28T08:31:57.545154Z",
     "iopub.status.idle": "2023-01-28T08:31:57.846600Z",
     "shell.execute_reply": "2023-01-28T08:31:57.845411Z"
    },
    "papermill": {
     "duration": 0.338476,
     "end_time": "2023-01-28T08:31:57.849339",
     "exception": false,
     "start_time": "2023-01-28T08:31:57.510863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(predCB).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7bf8310a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:31:57.892411Z",
     "iopub.status.busy": "2023-01-28T08:31:57.891265Z",
     "iopub.status.idle": "2023-01-28T08:31:58.324483Z",
     "shell.execute_reply": "2023-01-28T08:31:58.323288Z"
    },
    "papermill": {
     "duration": 0.457263,
     "end_time": "2023-01-28T08:31:58.326966",
     "exception": false,
     "start_time": "2023-01-28T08:31:57.869703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(predXB).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ceece902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:31:58.370792Z",
     "iopub.status.busy": "2023-01-28T08:31:58.370415Z",
     "iopub.status.idle": "2023-01-28T08:31:58.674767Z",
     "shell.execute_reply": "2023-01-28T08:31:58.673537Z"
    },
    "papermill": {
     "duration": 0.331252,
     "end_time": "2023-01-28T08:31:58.679499",
     "exception": false,
     "start_time": "2023-01-28T08:31:58.348247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(predCBC).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6469715",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:31:58.746680Z",
     "iopub.status.busy": "2023-01-28T08:31:58.745932Z",
     "iopub.status.idle": "2023-01-28T08:31:59.051846Z",
     "shell.execute_reply": "2023-01-28T08:31:59.050597Z"
    },
    "papermill": {
     "duration": 0.343782,
     "end_time": "2023-01-28T08:31:59.055310",
     "exception": false,
     "start_time": "2023-01-28T08:31:58.711528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(predXBC).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9f390ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:31:59.102731Z",
     "iopub.status.busy": "2023-01-28T08:31:59.102077Z",
     "iopub.status.idle": "2023-01-28T08:31:59.388221Z",
     "shell.execute_reply": "2023-01-28T08:31:59.387426Z"
    },
    "papermill": {
     "duration": 0.311753,
     "end_time": "2023-01-28T08:31:59.390803",
     "exception": false,
     "start_time": "2023-01-28T08:31:59.079050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(predLBC).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ecc3a1f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:31:59.435023Z",
     "iopub.status.busy": "2023-01-28T08:31:59.433994Z",
     "iopub.status.idle": "2023-01-28T08:31:59.717885Z",
     "shell.execute_reply": "2023-01-28T08:31:59.716699Z"
    },
    "papermill": {
     "duration": 0.308746,
     "end_time": "2023-01-28T08:31:59.720512",
     "exception": false,
     "start_time": "2023-01-28T08:31:59.411766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(predLB).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fd359dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:31:59.766150Z",
     "iopub.status.busy": "2023-01-28T08:31:59.765726Z",
     "iopub.status.idle": "2023-01-28T08:32:00.066217Z",
     "shell.execute_reply": "2023-01-28T08:32:00.065297Z"
    },
    "papermill": {
     "duration": 0.326428,
     "end_time": "2023-01-28T08:32:00.068852",
     "exception": false,
     "start_time": "2023-01-28T08:31:59.742424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predLR = np.average(np.array(predsLR),axis=0).clip(0,1)\n",
    "pd.Series(predLR).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6dc1c01c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:32:00.118517Z",
     "iopub.status.busy": "2023-01-28T08:32:00.118081Z",
     "iopub.status.idle": "2023-01-28T08:32:00.394839Z",
     "shell.execute_reply": "2023-01-28T08:32:00.393695Z"
    },
    "papermill": {
     "duration": 0.30394,
     "end_time": "2023-01-28T08:32:00.397232",
     "exception": false,
     "start_time": "2023-01-28T08:32:00.093292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(pred).hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53e93bd",
   "metadata": {
    "papermill": {
     "duration": 0.02183,
     "end_time": "2023-01-28T08:32:00.441534",
     "exception": false,
     "start_time": "2023-01-28T08:32:00.419704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Making submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "52b82aee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:32:00.487793Z",
     "iopub.status.busy": "2023-01-28T08:32:00.487014Z",
     "iopub.status.idle": "2023-01-28T08:32:00.499510Z",
     "shell.execute_reply": "2023-01-28T08:32:00.498694Z"
    },
    "papermill": {
     "duration": 0.03873,
     "end_time": "2023-01-28T08:32:00.502166",
     "exception": false,
     "start_time": "2023-01-28T08:32:00.463436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>219129</td>\n",
       "      <td>0.006258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>219130</td>\n",
       "      <td>0.003191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>219131</td>\n",
       "      <td>0.002079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>219132</td>\n",
       "      <td>0.004002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>219133</td>\n",
       "      <td>0.002473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146082</th>\n",
       "      <td>365211</td>\n",
       "      <td>0.001955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146083</th>\n",
       "      <td>365212</td>\n",
       "      <td>0.002399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146084</th>\n",
       "      <td>365213</td>\n",
       "      <td>0.002548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146085</th>\n",
       "      <td>365214</td>\n",
       "      <td>0.001790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146086</th>\n",
       "      <td>365215</td>\n",
       "      <td>0.002993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146087 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id     Class\n",
       "0       219129  0.006258\n",
       "1       219130  0.003191\n",
       "2       219131  0.002079\n",
       "3       219132  0.004002\n",
       "4       219133  0.002473\n",
       "...        ...       ...\n",
       "146082  365211  0.001955\n",
       "146083  365212  0.002399\n",
       "146084  365213  0.002548\n",
       "146085  365214  0.001790\n",
       "146086  365215  0.002993\n",
       "\n",
       "[146087 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['Class'] = pred\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74d30ce4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T08:32:00.549910Z",
     "iopub.status.busy": "2023-01-28T08:32:00.549104Z",
     "iopub.status.idle": "2023-01-28T08:32:00.916338Z",
     "shell.execute_reply": "2023-01-28T08:32:00.915101Z"
    },
    "papermill": {
     "duration": 0.394064,
     "end_time": "2023-01-28T08:32:00.919282",
     "exception": false,
     "start_time": "2023-01-28T08:32:00.525218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaskRestAPI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2215.522988,
   "end_time": "2023-01-28T08:32:02.171736",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-01-28T07:55:06.648748",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "f24fd3041fd0ddc911e946883510515a50d3f722f67cfcc69bf96ca687956574"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
